{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: MSZoning, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAndle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope      ...      OpenPorchSF EnclosedPorch  \\\n",
       "0    AllPub    Inside       Gtl      ...                0             0   \n",
       "1    AllPub    Corner       Gtl      ...               36             0   \n",
       "2    AllPub    Inside       Gtl      ...               34             0   \n",
       "3    AllPub    Inside       Gtl      ...               36             0   \n",
       "4    AllPub    Inside       Gtl      ...               82             0   \n",
       "\n",
       "  3SsnPorch ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType  \\\n",
       "0         0         120        0        0       6    2010        WD   \n",
       "1         0           0        0    12500       6    2010        WD   \n",
       "2         0           0        0        0       3    2010        WD   \n",
       "3         0           0        0        0       6    2010        WD   \n",
       "4         0         144        0        0       1    2010        WD   \n",
       "\n",
       "  SaleCondition  \n",
       "0        Normal  \n",
       "1        Normal  \n",
       "2        Normal  \n",
       "3        Normal  \n",
       "4        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "5       143000.0\n",
       "6       307000.0\n",
       "7       200000.0\n",
       "8       129900.0\n",
       "9       118000.0\n",
       "10      129500.0\n",
       "11      345000.0\n",
       "12      144000.0\n",
       "13      279500.0\n",
       "14      157000.0\n",
       "15      132000.0\n",
       "16      149000.0\n",
       "18      159000.0\n",
       "19      139000.0\n",
       "20      325300.0\n",
       "21      139400.0\n",
       "22      230000.0\n",
       "23      129900.0\n",
       "24      154000.0\n",
       "25      256300.0\n",
       "26      134800.0\n",
       "27      306000.0\n",
       "28      207500.0\n",
       "29       68500.0\n",
       "30       40000.0\n",
       "          ...   \n",
       "1429         NaN\n",
       "1430         NaN\n",
       "1431         NaN\n",
       "1432         NaN\n",
       "1433         NaN\n",
       "1434         NaN\n",
       "1435         NaN\n",
       "1436         NaN\n",
       "1437         NaN\n",
       "1438         NaN\n",
       "1439         NaN\n",
       "1440         NaN\n",
       "1441         NaN\n",
       "1442         NaN\n",
       "1443         NaN\n",
       "1444         NaN\n",
       "1445         NaN\n",
       "1446         NaN\n",
       "1447         NaN\n",
       "1448         NaN\n",
       "1449         NaN\n",
       "1450         NaN\n",
       "1451         NaN\n",
       "1452         NaN\n",
       "1453         NaN\n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>796</td>\n",
       "      <td>566</td>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1107</td>\n",
       "      <td>983</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>859.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1022</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>851.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1182</td>\n",
       "      <td>1142</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>733.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>578.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1158</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>188.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>234.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>649</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>967</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1060</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>576</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>909.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>616</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>996</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0          856       854          0             3       706.0         0.0   \n",
       "1         1262         0          0             3       978.0         0.0   \n",
       "2          920       866          0             3       486.0         0.0   \n",
       "3          961       756          0             3       216.0         0.0   \n",
       "4         1145      1053          0             4       655.0         0.0   \n",
       "5          796       566        320             1       732.0         0.0   \n",
       "6         1694         0          0             3      1369.0         0.0   \n",
       "7         1107       983          0             3       859.0        32.0   \n",
       "8         1022       752          0             2         0.0         0.0   \n",
       "9         1077         0          0             2       851.0         0.0   \n",
       "10        1040         0          0             3       906.0         0.0   \n",
       "11        1182      1142          0             4       998.0         0.0   \n",
       "12         912         0          0             2       737.0         0.0   \n",
       "13        1494         0          0             3         0.0         0.0   \n",
       "14        1253         0          0             2       733.0         0.0   \n",
       "15         854         0          0             2         0.0         0.0   \n",
       "16        1004         0          0             2       578.0         0.0   \n",
       "18        1114         0          0             3       646.0         0.0   \n",
       "19        1339         0          0             3       504.0         0.0   \n",
       "20        1158      1218          0             4         0.0         0.0   \n",
       "21        1108         0          0             3         0.0         0.0   \n",
       "22        1795         0          0             3         0.0         0.0   \n",
       "23        1060         0          0             3       840.0         0.0   \n",
       "24        1060         0          0             3       188.0       668.0   \n",
       "25        1600         0          0             3         0.0         0.0   \n",
       "26         900         0          0             3       234.0       486.0   \n",
       "27        1704         0          0             3      1218.0         0.0   \n",
       "28        1600         0          0             2      1277.0         0.0   \n",
       "29         520         0          0             1         0.0         0.0   \n",
       "30         649       668          0             3         0.0         0.0   \n",
       "...        ...       ...        ...           ...         ...         ...   \n",
       "1429       641         0          0             2         0.0         0.0   \n",
       "1430       967       671          0             4         0.0         0.0   \n",
       "1431       729         0          0             2         0.0         0.0   \n",
       "1432      1060       336          0             4         0.0         0.0   \n",
       "1433       576       360          0             2         0.0         0.0   \n",
       "1434      1778         0          0             2      1573.0         0.0   \n",
       "1435      1646         0          0             2      1564.0         0.0   \n",
       "1436      1625         0          0             3       776.0         0.0   \n",
       "1437      1664         0          0             4         0.0         0.0   \n",
       "1438      1491         0          0             3         0.0         0.0   \n",
       "1439      1210         0          0             3       576.0         0.0   \n",
       "1440      1650         0          0             2       909.0         0.0   \n",
       "1441      1403         0          0             2      1136.0       116.0   \n",
       "1442      1960         0          0             3      1350.0         0.0   \n",
       "1443      1838         0          0             3      1455.0         0.0   \n",
       "1444      1600         0          0             3         0.0         0.0   \n",
       "1445      1368         0          0             2      1243.0         0.0   \n",
       "1446       616       688          0             3         0.0         0.0   \n",
       "1447       874         0          0             3       441.0         0.0   \n",
       "1448      1652         0          0             4       149.0         0.0   \n",
       "1449       630         0          0             1       522.0         0.0   \n",
       "1450       546       546          0             3       252.0         0.0   \n",
       "1451      1360         0          0             3       119.0       344.0   \n",
       "1452       546       546          0             3       408.0         0.0   \n",
       "1453       546       546          0             3         0.0         0.0   \n",
       "1454       546       546          0             3         0.0         0.0   \n",
       "1455       546       546          0             3       252.0         0.0   \n",
       "1456      1224         0          0             4      1224.0         0.0   \n",
       "1457       970         0          0             3       337.0         0.0   \n",
       "1458       996      1004          0             3       758.0         0.0   \n",
       "\n",
       "      BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  \\\n",
       "0              1.0           0.0      150.0              0 ...     0     0   \n",
       "1              0.0           1.0      284.0              0 ...     0     0   \n",
       "2              1.0           0.0      434.0              0 ...     0     0   \n",
       "3              1.0           0.0      540.0            272 ...     0     0   \n",
       "4              1.0           0.0      490.0              0 ...     0     0   \n",
       "5              1.0           0.0       64.0              0 ...     0     0   \n",
       "6              1.0           0.0      317.0              0 ...     0     0   \n",
       "7              1.0           0.0      216.0            228 ...     0     0   \n",
       "8              0.0           0.0      952.0            205 ...     1     0   \n",
       "9              1.0           0.0      140.0              0 ...     0     0   \n",
       "10             1.0           0.0      134.0              0 ...     0     0   \n",
       "11             1.0           0.0      177.0              0 ...     0     0   \n",
       "12             1.0           0.0      175.0              0 ...     0     0   \n",
       "13             0.0           0.0     1494.0              0 ...     0     0   \n",
       "14             1.0           0.0      520.0            176 ...     0     0   \n",
       "15             0.0           0.0      832.0              0 ...     0     0   \n",
       "16             1.0           0.0      426.0              0 ...     0     0   \n",
       "18             1.0           0.0      468.0              0 ...     0     0   \n",
       "19             0.0           0.0      525.0              0 ...     1     0   \n",
       "20             0.0           0.0     1158.0              0 ...     0     0   \n",
       "21             0.0           0.0      637.0            205 ...     0     0   \n",
       "22             0.0           0.0     1777.0              0 ...     0     0   \n",
       "23             1.0           0.0      200.0              0 ...     0     0   \n",
       "24             1.0           0.0      204.0              0 ...     0     0   \n",
       "25             0.0           0.0     1566.0              0 ...     0     0   \n",
       "26             0.0           1.0      180.0              0 ...     0     0   \n",
       "27             1.0           0.0      486.0              0 ...     0     0   \n",
       "28             1.0           0.0      207.0              0 ...     0     0   \n",
       "29             0.0           0.0      520.0             87 ...     0     0   \n",
       "30             0.0           0.0      649.0            172 ...     0     0   \n",
       "...            ...           ...        ...            ... ...   ...   ...   \n",
       "1429           0.0           0.0      641.0             70 ...     0     0   \n",
       "1430           0.0           0.0      967.0              0 ...     0     0   \n",
       "1431           0.0           0.0        0.0             23 ...     0     0   \n",
       "1432           0.0           0.0      660.0              0 ...     0     1   \n",
       "1433           0.0           0.0      216.0              0 ...     0     0   \n",
       "1434           2.0           0.0        0.0              0 ...     0     0   \n",
       "1435           1.0           1.0       30.0              0 ...     0     0   \n",
       "1436           0.0           1.0      849.0              0 ...     0     0   \n",
       "1437           0.0           0.0     1664.0              0 ...     0     0   \n",
       "1438           0.0           0.0     1491.0              0 ...     0     0   \n",
       "1439           1.0           0.0      552.0              0 ...     0     0   \n",
       "1440           1.0           0.0      723.0              0 ...     0     0   \n",
       "1441           1.0           0.0      129.0              0 ...     0     0   \n",
       "1442           1.0           0.0      378.0              0 ...     0     0   \n",
       "1443           1.0           0.0      383.0              0 ...     0     0   \n",
       "1444           0.0           0.0        0.0            135 ...     0     0   \n",
       "1445           2.0           0.0       45.0              0 ...     0     0   \n",
       "1446           0.0           0.0      264.0              0 ...     0     0   \n",
       "1447           1.0           0.0      423.0              0 ...     0     0   \n",
       "1448           0.0           0.0     1503.0              0 ...     0     0   \n",
       "1449           1.0           0.0      108.0              0 ...     0     0   \n",
       "1450           0.0           0.0      294.0              0 ...     0     0   \n",
       "1451           1.0           0.0      641.0              0 ...     0     0   \n",
       "1452           0.0           0.0      138.0              0 ...     0     0   \n",
       "1453           0.0           0.0      546.0              0 ...     0     0   \n",
       "1454           0.0           0.0      546.0              0 ...     0     0   \n",
       "1455           0.0           0.0      294.0              0 ...     0     0   \n",
       "1456           1.0           0.0        0.0              0 ...     0     0   \n",
       "1457           0.0           1.0      575.0              0 ...     0     0   \n",
       "1458           0.0           0.0      238.0              0 ...     0     0   \n",
       "\n",
       "      Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1       1        0        0        0       0    1  0  \n",
       "1       1       1        0        0        0       0    1  0  \n",
       "2       1       1        0        0        0       0    1  0  \n",
       "3       1       0        0        0        0       1    0  0  \n",
       "4       1       1        0        0        0       0    1  0  \n",
       "5       1       1        0        0        0       0    0  0  \n",
       "6       1       1        0        0        0       0    1  0  \n",
       "7       1       1        0        0        0       0    1  0  \n",
       "8       0       0        0        0        0       1    0  0  \n",
       "9       1       1        0        0        0       0    1  0  \n",
       "10      1       0        0        0        0       1    0  0  \n",
       "11      1       0        0        1        0       0    0  0  \n",
       "12      1       0        0        0        0       1    0  0  \n",
       "13      1       1        0        0        0       0    1  0  \n",
       "14      1       1        0        0        0       0    1  0  \n",
       "15      1       0        0        0        0       1    0  0  \n",
       "16      1       1        0        0        0       0    0  0  \n",
       "18      1       0        0        0        0       1    0  0  \n",
       "19      0       1        0        0        0       0    0  0  \n",
       "20      1       0        0        1        0       0    1  0  \n",
       "21      1       1        0        0        0       0    0  0  \n",
       "22      1       1        0        0        0       0    1  0  \n",
       "23      1       1        0        0        0       0    0  0  \n",
       "24      1       1        0        0        0       0    0  0  \n",
       "25      1       1        0        0        0       0    1  0  \n",
       "26      1       0        0        0        0       1    0  0  \n",
       "27      1       1        0        0        0       0    1  0  \n",
       "28      1       1        0        0        0       0    1  0  \n",
       "29      1       0        0        0        0       1    0  0  \n",
       "30      1       0        0        0        0       1    0  0  \n",
       "...   ...     ...      ...      ...      ...     ...  ... ..  \n",
       "1429    1       0        0        0        0       1    0  0  \n",
       "1430    1       0        0        0        0       1    0  0  \n",
       "1431    0       1        0        0        0       0    0  0  \n",
       "1432    0       1        0        0        0       0    0  0  \n",
       "1433    1       1        0        0        0       0    0  0  \n",
       "1434    1       1        0        0        0       0    0  0  \n",
       "1435    1       1        0        0        0       0    0  0  \n",
       "1436    1       1        0        0        0       0    0  0  \n",
       "1437    1       0        0        0        0       0    0  0  \n",
       "1438    1       1        0        0        0       0    1  0  \n",
       "1439    1       1        0        0        0       0    0  0  \n",
       "1440    1       1        0        0        0       0    0  0  \n",
       "1441    1       1        0        0        0       0    0  0  \n",
       "1442    1       1        0        0        0       0    0  0  \n",
       "1443    1       1        0        0        0       0    0  0  \n",
       "1444    0       1        0        0        0       0    0  0  \n",
       "1445    1       1        0        0        0       0    0  0  \n",
       "1446    1       0        0        1        0       0    1  0  \n",
       "1447    1       1        0        0        0       0    1  0  \n",
       "1448    1       0        0        0        0       0    0  0  \n",
       "1449    1       1        0        0        0       0    0  0  \n",
       "1450    1       1        0        0        0       0    0  0  \n",
       "1451    1       1        0        0        0       0    1  0  \n",
       "1452    1       0        0        0        1       0    0  0  \n",
       "1453    1       1        0        0        0       0    0  0  \n",
       "1454    1       1        0        0        0       0    0  0  \n",
       "1455    1       0        0        0        1       0    0  0  \n",
       "1456    1       0        0        0        0       1    0  0  \n",
       "1457    1       1        0        0        0       0    0  0  \n",
       "1458    1       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0             3       706.0         0.0   \n",
       "1      1262         0          0             3       978.0         0.0   \n",
       "2       920       866          0             3       486.0         0.0   \n",
       "3       961       756          0             3       216.0         0.0   \n",
       "4      1145      1053          0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           1.0           0.0      150.0              0 ...     0     0    1   \n",
       "1           0.0           1.0      284.0              0 ...     0     0    1   \n",
       "2           1.0           0.0      434.0              0 ...     0     0    1   \n",
       "3           1.0           0.0      540.0            272 ...     0     0    1   \n",
       "4           1.0           0.0      490.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciton and selecting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=4,\n",
       "          param_distributions={'n_estimators': [100, 500, 900, 1100, 1500], 'max_depth': [2, 3, 5, 10, 15], 'learning_rate': [0.05, 0.1, 0.15, 0.2], 'min_child_weight': [1, 2, 3, 4], 'booster': ['gbtree', 'gblinear'], 'base_score': [0.25, 0.5, 0.75, 1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "          verbose=5)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119179.125, 158328.88 , 183704.81 , ..., 165757.22 , 118693.11 ,\n",
       "       230294.19 ], dtype=float32)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.columns=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=df_Train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.column=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test=pd.concat([df_Test,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 175)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,df_Test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2304 samples, validate on 577 samples\n",
      "Epoch 1/1000\n",
      "2304/2304 [==============================] - 2s 1ms/step - loss: 113530.5093 - val_loss: 56624.8765\n",
      "Epoch 2/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 62615.1298 - val_loss: 50444.1900\n",
      "Epoch 3/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 56279.5739 - val_loss: 44504.8296\n",
      "Epoch 4/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 50261.0310 - val_loss: 39335.5723\n",
      "Epoch 5/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 44449.5163 - val_loss: 35396.5539\n",
      "Epoch 6/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 40090.4315 - val_loss: 35178.2237\n",
      "Epoch 7/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 37493.4126 - val_loss: 31983.3301\n",
      "Epoch 8/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 36462.1401 - val_loss: 34241.1639\n",
      "Epoch 9/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 35635.4539 - val_loss: 32087.6040\n",
      "Epoch 10/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 35851.5885 - val_loss: 32125.1113\n",
      "Epoch 11/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 35622.6530 - val_loss: 31914.6602\n",
      "Epoch 12/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 35187.7144 - val_loss: 31882.3983\n",
      "Epoch 13/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 35196.1213 - val_loss: 32342.4395\n",
      "Epoch 14/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 34929.6660 - val_loss: 31565.0875\n",
      "Epoch 15/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 34672.9052 - val_loss: 32177.3833\n",
      "Epoch 16/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 34501.2563 - val_loss: 31293.5959\n",
      "Epoch 17/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 34804.2316 - val_loss: 31182.3204\n",
      "Epoch 18/1000\n",
      "2304/2304 [==============================] - 2s 778us/step - loss: 34455.4584 - val_loss: 31376.9020\n",
      "Epoch 19/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 34377.8071 - val_loss: 31301.4047\n",
      "Epoch 20/1000\n",
      "2304/2304 [==============================] - 1s 477us/step - loss: 34164.2543 - val_loss: 31142.9020\n",
      "Epoch 21/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 34009.0316 - val_loss: 31243.3016\n",
      "Epoch 22/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 33660.4401 - val_loss: 31494.8445\n",
      "Epoch 23/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 33812.4372 - val_loss: 31299.1932\n",
      "Epoch 24/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 33589.9288 - val_loss: 31848.2731\n",
      "Epoch 25/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 33607.1809 - val_loss: 30390.6748\n",
      "Epoch 26/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 33473.9579 - val_loss: 30910.1593\n",
      "Epoch 27/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 33236.2349 - val_loss: 30219.5441\n",
      "Epoch 28/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 33243.2710 - val_loss: 30179.0993\n",
      "Epoch 29/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 32929.2295 - val_loss: 30128.3545\n",
      "Epoch 30/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32963.0511 - val_loss: 30510.0357\n",
      "Epoch 31/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 32787.1626 - val_loss: 29853.5188\n",
      "Epoch 32/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 32766.8486 - val_loss: 30704.6890\n",
      "Epoch 33/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 32790.5330 - val_loss: 30381.5674\n",
      "Epoch 34/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 32740.6885 - val_loss: 29614.6660\n",
      "Epoch 35/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32658.3221 - val_loss: 30323.1913\n",
      "Epoch 36/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 32570.0888 - val_loss: 30407.4534\n",
      "Epoch 37/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32189.7531 - val_loss: 30379.3509\n",
      "Epoch 38/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 32140.4911 - val_loss: 29347.5356\n",
      "Epoch 39/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 31913.3835 - val_loss: 29861.8741\n",
      "Epoch 40/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 32135.0634 - val_loss: 29108.2475\n",
      "Epoch 41/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32026.9856 - val_loss: 29142.3169\n",
      "Epoch 42/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 31792.7488 - val_loss: 29323.2182\n",
      "Epoch 43/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 31622.7127 - val_loss: 29028.4757\n",
      "Epoch 44/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 31769.7568 - val_loss: 29493.1864\n",
      "Epoch 45/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 31732.7656 - val_loss: 29812.4935\n",
      "Epoch 46/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 31434.8387 - val_loss: 28903.6488\n",
      "Epoch 47/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 31234.3539 - val_loss: 28895.0965\n",
      "Epoch 48/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 31151.4855 - val_loss: 28861.3638\n",
      "Epoch 49/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 31274.5573 - val_loss: 29427.3137\n",
      "Epoch 50/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 31510.8220 - val_loss: 28567.3384\n",
      "Epoch 51/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 31460.1977 - val_loss: 28814.4977\n",
      "Epoch 52/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 31085.8429 - val_loss: 28524.2395\n",
      "Epoch 53/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30989.9977 - val_loss: 28568.5788\n",
      "Epoch 54/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 31092.4584 - val_loss: 28378.7455\n",
      "Epoch 55/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 30932.9268 - val_loss: 30094.5473\n",
      "Epoch 56/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30684.4676 - val_loss: 28414.4087\n",
      "Epoch 57/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 30493.6564 - val_loss: 29508.0253\n",
      "Epoch 58/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 30652.6024 - val_loss: 28326.5143\n",
      "Epoch 59/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30778.1669 - val_loss: 28056.4234\n",
      "Epoch 60/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 30424.7307 - val_loss: 28010.0378\n",
      "Epoch 61/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 30072.8579 - val_loss: 28027.6187\n",
      "Epoch 62/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30334.3219 - val_loss: 28459.9857\n",
      "Epoch 63/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30427.8750 - val_loss: 29863.5684\n",
      "Epoch 64/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30285.2018 - val_loss: 28957.1549\n",
      "Epoch 65/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 30310.4877 - val_loss: 28183.0357\n",
      "Epoch 66/1000\n",
      "2304/2304 [==============================] - 1s 405us/step - loss: 30276.2501 - val_loss: 27665.3018\n",
      "Epoch 67/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29832.1718 - val_loss: 27712.5372\n",
      "Epoch 68/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 30272.4041 - val_loss: 27718.7824\n",
      "Epoch 69/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 30113.7119 - val_loss: 28000.3839\n",
      "Epoch 70/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29942.6214 - val_loss: 27786.2428\n",
      "Epoch 71/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 29859.0674 - val_loss: 27215.5401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29209.5491 - val_loss: 27173.5760\n",
      "Epoch 73/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 29919.4843 - val_loss: 27220.3691\n",
      "Epoch 74/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 29509.6134 - val_loss: 27340.0882\n",
      "Epoch 75/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 29708.4845 - val_loss: 27312.6990\n",
      "Epoch 76/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 29519.9725 - val_loss: 27508.6494\n",
      "Epoch 77/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29357.4566 - val_loss: 26867.6287\n",
      "Epoch 78/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29159.6736 - val_loss: 26893.8640\n",
      "Epoch 79/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 29366.9112 - val_loss: 26603.1912\n",
      "Epoch 80/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 29120.4931 - val_loss: 26661.9235\n",
      "Epoch 81/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 28946.7935 - val_loss: 27871.8099\n",
      "Epoch 82/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 29138.3855 - val_loss: 26531.3914\n",
      "Epoch 83/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 28846.1910 - val_loss: 28481.5947\n",
      "Epoch 84/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29017.1691 - val_loss: 26508.0993\n",
      "Epoch 85/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 28775.6919 - val_loss: 26779.5843\n",
      "Epoch 86/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 29089.2547 - val_loss: 27172.3217\n",
      "Epoch 87/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 28686.1871 - val_loss: 26091.4350\n",
      "Epoch 88/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28698.4660 - val_loss: 26102.4028\n",
      "Epoch 89/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 28699.3697 - val_loss: 26289.4353\n",
      "Epoch 90/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 28489.5871 - val_loss: 27897.5505\n",
      "Epoch 91/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 28665.1914 - val_loss: 25854.9589\n",
      "Epoch 92/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 28285.7090 - val_loss: 25977.9663\n",
      "Epoch 93/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 28285.7983 - val_loss: 25438.4628\n",
      "Epoch 94/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28321.3720 - val_loss: 25585.6818\n",
      "Epoch 95/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 28190.3902 - val_loss: 25334.2817\n",
      "Epoch 96/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 28360.6425 - val_loss: 25095.3392\n",
      "Epoch 97/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 28196.4608 - val_loss: 24977.6499\n",
      "Epoch 98/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 28143.1103 - val_loss: 24957.5144\n",
      "Epoch 99/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 28541.725 - 1s 465us/step - loss: 28404.1788 - val_loss: 25377.6330\n",
      "Epoch 100/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 27923.1122 - val_loss: 25035.9833\n",
      "Epoch 101/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 28224.6294 - val_loss: 24864.9644\n",
      "Epoch 102/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27838.1132 - val_loss: 26435.8536\n",
      "Epoch 103/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 27936.2079 - val_loss: 24885.9012\n",
      "Epoch 104/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 27583.212 - 1s 450us/step - loss: 27619.0787 - val_loss: 24613.4044\n",
      "Epoch 105/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 27628.1560 - val_loss: 24228.4823\n",
      "Epoch 106/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 27878.6943 - val_loss: 24845.3175\n",
      "Epoch 107/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 27493.7438 - val_loss: 24612.2324\n",
      "Epoch 108/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 27134.2120 - val_loss: 25914.3079\n",
      "Epoch 109/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 27448.0619 - val_loss: 23640.7174\n",
      "Epoch 110/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 27225.6602 - val_loss: 24300.4790\n",
      "Epoch 111/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 27457.5783 - val_loss: 23591.0836\n",
      "Epoch 112/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27562.5854 - val_loss: 23601.4916\n",
      "Epoch 113/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 26970.8130 - val_loss: 23496.5879\n",
      "Epoch 114/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 27141.8372 - val_loss: 24716.6597\n",
      "Epoch 115/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 26687.5030 - val_loss: 25936.5065\n",
      "Epoch 116/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 26811.0217 - val_loss: 23067.7963\n",
      "Epoch 117/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 26862.9685 - val_loss: 23789.6916\n",
      "Epoch 118/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 26478.2679 - val_loss: 24595.6749\n",
      "Epoch 119/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 26766.5188 - val_loss: 23377.8840\n",
      "Epoch 120/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 26545.6570 - val_loss: 22453.2940\n",
      "Epoch 121/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 26442.3213 - val_loss: 22567.1628\n",
      "Epoch 122/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 26011.6722 - val_loss: 24087.4123\n",
      "Epoch 123/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 26506.6031 - val_loss: 22453.8540\n",
      "Epoch 124/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 26042.1024 - val_loss: 22348.5490\n",
      "Epoch 125/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 26685.7815 - val_loss: 21968.0753\n",
      "Epoch 126/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 25654.7254 - val_loss: 22398.2175\n",
      "Epoch 127/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 25909.7507 - val_loss: 21961.1548\n",
      "Epoch 128/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 25938.8809 - val_loss: 21437.6150\n",
      "Epoch 129/1000\n",
      "2304/2304 [==============================] - 1s 476us/step - loss: 25268.5747 - val_loss: 21907.7049\n",
      "Epoch 130/1000\n",
      "2304/2304 [==============================] - 1s 470us/step - loss: 25609.2470 - val_loss: 21246.5780\n",
      "Epoch 131/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 25023.4624 - val_loss: 24637.6923\n",
      "Epoch 132/1000\n",
      "2304/2304 [==============================] - 1s 520us/step - loss: 25366.8912 - val_loss: 21211.1705\n",
      "Epoch 133/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 25424.9557 - val_loss: 21021.8191\n",
      "Epoch 134/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 25343.5929 - val_loss: 21586.6650\n",
      "Epoch 135/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 24995.2175 - val_loss: 21105.6569\n",
      "Epoch 136/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 24986.7363 - val_loss: 20605.5033\n",
      "Epoch 137/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 25225.4030 - val_loss: 20552.5941\n",
      "Epoch 138/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 25014.9195 - val_loss: 21813.1205\n",
      "Epoch 139/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 24983.0982 - val_loss: 20684.3204\n",
      "Epoch 140/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 24864.2334 - val_loss: 20245.8430\n",
      "Epoch 141/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 24915.6213 - val_loss: 19954.3808\n",
      "Epoch 142/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 24832.0423 - val_loss: 22799.6597\n",
      "Epoch 143/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 24758.2035 - val_loss: 20148.5544\n",
      "Epoch 144/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 24726.4656 - val_loss: 19816.7254\n",
      "Epoch 145/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24342.4105 - val_loss: 21506.8392\n",
      "Epoch 146/1000\n",
      "2304/2304 [==============================] - 1s 494us/step - loss: 24704.4509 - val_loss: 19672.9874\n",
      "Epoch 147/1000\n",
      "2304/2304 [==============================] - 1s 483us/step - loss: 24873.8309 - val_loss: 19765.3019\n",
      "Epoch 148/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 24126.7666 - val_loss: 21504.0878\n",
      "Epoch 149/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24424.1095 - val_loss: 21462.0763\n",
      "Epoch 150/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 24470.7238 - val_loss: 19617.8413\n",
      "Epoch 151/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 24235.2767 - val_loss: 20478.6877\n",
      "Epoch 152/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 23886.3026 - val_loss: 19679.8546\n",
      "Epoch 153/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 24203.4083 - val_loss: 19225.7126\n",
      "Epoch 154/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 24125.6937 - val_loss: 18712.8627\n",
      "Epoch 155/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 23699.3783 - val_loss: 19005.6716\n",
      "Epoch 156/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23628.8058 - val_loss: 20574.2034\n",
      "Epoch 157/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 23527.5995 - val_loss: 20440.9397\n",
      "Epoch 158/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 23367.5987 - val_loss: 20027.8654\n",
      "Epoch 159/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23393.3923 - val_loss: 18406.9154\n",
      "Epoch 160/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 23547.7516 - val_loss: 19510.1907\n",
      "Epoch 161/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23700.4968 - val_loss: 19711.2351\n",
      "Epoch 162/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23521.9805 - val_loss: 19353.0765\n",
      "Epoch 163/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 23289.4974 - val_loss: 18495.0024\n",
      "Epoch 164/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 23146.1177 - val_loss: 18525.8958\n",
      "Epoch 165/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 23378.2289 - val_loss: 18674.6753\n",
      "Epoch 166/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 22990.6150 - val_loss: 18405.3405\n",
      "Epoch 167/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 23208.1085 - val_loss: 18444.8079\n",
      "Epoch 168/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23341.9950 - val_loss: 18214.6930\n",
      "Epoch 169/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22968.4293 - val_loss: 18287.0789\n",
      "Epoch 170/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 23336.9285 - val_loss: 19328.6353\n",
      "Epoch 171/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23004.5811 - val_loss: 22645.0320\n",
      "Epoch 172/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 23450.7607 - val_loss: 18237.4190\n",
      "Epoch 173/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 23322.7922 - val_loss: 18528.1455\n",
      "Epoch 174/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 22646.3451 - val_loss: 18115.4026\n",
      "Epoch 175/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22568.9873 - val_loss: 19539.2561\n",
      "Epoch 176/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 23544.2008 - val_loss: 17933.2717\n",
      "Epoch 177/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22497.0116 - val_loss: 17354.5006\n",
      "Epoch 178/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22879.9811 - val_loss: 17579.1927\n",
      "Epoch 179/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22938.6665 - val_loss: 18413.8741\n",
      "Epoch 180/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22665.2603 - val_loss: 19428.7250\n",
      "Epoch 181/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22319.2484 - val_loss: 17366.1969\n",
      "Epoch 182/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22669.5232 - val_loss: 18838.8342\n",
      "Epoch 183/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22451.1597 - val_loss: 18472.8874\n",
      "Epoch 184/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22706.7617 - val_loss: 18255.4424\n",
      "Epoch 185/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22957.0078 - val_loss: 17473.3416\n",
      "Epoch 186/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22531.9464 - val_loss: 16844.6493\n",
      "Epoch 187/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 22240.5742 - val_loss: 17564.5887\n",
      "Epoch 188/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22642.6283 - val_loss: 17112.6908\n",
      "Epoch 189/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 22320.6819 - val_loss: 17639.8543\n",
      "Epoch 190/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22117.3255 - val_loss: 17005.3269\n",
      "Epoch 191/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22249.5553 - val_loss: 18395.3013\n",
      "Epoch 192/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 22401.0267 - val_loss: 16680.4410\n",
      "Epoch 193/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 22384.8159 - val_loss: 17162.2615\n",
      "Epoch 194/1000\n",
      "2304/2304 [==============================] - 1s 475us/step - loss: 21983.3552 - val_loss: 18605.2577\n",
      "Epoch 195/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22257.2526 - val_loss: 17034.5954\n",
      "Epoch 196/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 22122.9456 - val_loss: 17328.9022\n",
      "Epoch 197/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22467.4348 - val_loss: 17312.1251\n",
      "Epoch 198/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22034.0424 - val_loss: 16346.6881\n",
      "Epoch 199/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 21772.8173 - val_loss: 16449.1762\n",
      "Epoch 200/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 21616.0995 - val_loss: 19556.2224\n",
      "Epoch 201/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 22326.2749 - val_loss: 16196.6720\n",
      "Epoch 202/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22678.2432 - val_loss: 16400.9500\n",
      "Epoch 203/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 21954.1421 - val_loss: 17115.8815\n",
      "Epoch 204/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21574.3031 - val_loss: 16127.1571\n",
      "Epoch 205/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22338.9508 - val_loss: 19444.3208\n",
      "Epoch 206/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21852.7934 - val_loss: 19308.3233\n",
      "Epoch 207/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 21872.5774 - val_loss: 17685.5849\n",
      "Epoch 208/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 21486.7361 - val_loss: 16639.5072\n",
      "Epoch 209/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21571.2908 - val_loss: 16761.9651\n",
      "Epoch 210/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 21631.3609 - val_loss: 15658.4923\n",
      "Epoch 211/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21486.4054 - val_loss: 15814.1505\n",
      "Epoch 212/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21541.5087 - val_loss: 17495.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 22039.3132 - val_loss: 18907.8804\n",
      "Epoch 214/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21535.5008 - val_loss: 16334.5270\n",
      "Epoch 215/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 21397.5464 - val_loss: 15527.8804\n",
      "Epoch 216/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20970.6127 - val_loss: 15893.2644\n",
      "Epoch 217/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21382.1890 - val_loss: 16356.3695\n",
      "Epoch 218/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21161.6115 - val_loss: 17358.3467\n",
      "Epoch 219/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 21313.9134 - val_loss: 16149.4819\n",
      "Epoch 220/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21500.9419 - val_loss: 15796.3191\n",
      "Epoch 221/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 21536.2349 - val_loss: 15471.1339\n",
      "Epoch 222/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 21088.8941 - val_loss: 15343.0244\n",
      "Epoch 223/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 21667.5794 - val_loss: 17580.5199\n",
      "Epoch 224/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20965.1858 - val_loss: 15803.6322\n",
      "Epoch 225/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21442.6807 - val_loss: 17598.5028\n",
      "Epoch 226/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 21107.7338 - val_loss: 15927.4279\n",
      "Epoch 227/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20982.8748 - val_loss: 16270.2747\n",
      "Epoch 228/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21420.9400 - val_loss: 15423.4538\n",
      "Epoch 229/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 20855.8819 - val_loss: 16644.8780\n",
      "Epoch 230/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 20768.6303 - val_loss: 15575.5588\n",
      "Epoch 231/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21261.2271 - val_loss: 16437.3966\n",
      "Epoch 232/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 21497.1832 - val_loss: 15420.6945\n",
      "Epoch 233/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 20544.3840 - val_loss: 15224.6794\n",
      "Epoch 234/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21233.0104 - val_loss: 15038.2329\n",
      "Epoch 235/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21491.5446 - val_loss: 17434.5473\n",
      "Epoch 236/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21326.1712 - val_loss: 16683.8884\n",
      "Epoch 237/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 21116.4700 - val_loss: 15612.9380\n",
      "Epoch 238/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22033.4280 - val_loss: 15167.3380\n",
      "Epoch 239/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21327.5555 - val_loss: 15373.3279\n",
      "Epoch 240/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 20829.2319 - val_loss: 15861.8656\n",
      "Epoch 241/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 20925.8254 - val_loss: 15428.4299\n",
      "Epoch 242/1000\n",
      "2304/2304 [==============================] - 1s 510us/step - loss: 21137.2842 - val_loss: 19346.3964\n",
      "Epoch 243/1000\n",
      "2304/2304 [==============================] - 1s 495us/step - loss: 20912.4358 - val_loss: 15086.4801\n",
      "Epoch 244/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20783.2399 - val_loss: 17047.4020\n",
      "Epoch 245/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20600.0964 - val_loss: 16235.3380\n",
      "Epoch 246/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20756.1085 - val_loss: 15630.0819\n",
      "Epoch 247/1000\n",
      "2304/2304 [==============================] - 1s 487us/step - loss: 20794.2793 - val_loss: 15813.6791\n",
      "Epoch 248/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 20578.2091 - val_loss: 14941.2435\n",
      "Epoch 249/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20526.0308 - val_loss: 17806.7003\n",
      "Epoch 250/1000\n",
      "2304/2304 [==============================] - 1s 583us/step - loss: 20334.8256 - val_loss: 18193.9887\n",
      "Epoch 251/1000\n",
      "2304/2304 [==============================] - 1s 530us/step - loss: 20293.9275 - val_loss: 17792.9437\n",
      "Epoch 252/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20567.1465 - val_loss: 15440.0669\n",
      "Epoch 253/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20427.0153 - val_loss: 14923.4824\n",
      "Epoch 254/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20450.5625 - val_loss: 16042.9484\n",
      "Epoch 255/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 20198.3318 - val_loss: 16222.9939\n",
      "Epoch 256/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 20533.8341 - val_loss: 16831.9639\n",
      "Epoch 257/1000\n",
      "2304/2304 [==============================] - 1s 509us/step - loss: 20154.9191 - val_loss: 14754.8845\n",
      "Epoch 258/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 20387.4427 - val_loss: 15878.7856\n",
      "Epoch 259/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20359.2988 - val_loss: 16003.4819\n",
      "Epoch 260/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20531.9542 - val_loss: 16200.7362\n",
      "Epoch 261/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 20018.3629 - val_loss: 15491.6521\n",
      "Epoch 262/1000\n",
      "2304/2304 [==============================] - 1s 481us/step - loss: 20267.9428 - val_loss: 15069.8928\n",
      "Epoch 263/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 20530.1369 - val_loss: 15627.3145\n",
      "Epoch 264/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20294.7257 - val_loss: 17765.7470\n",
      "Epoch 265/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 20360.8740 - val_loss: 14508.3821\n",
      "Epoch 266/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 20267.8221 - val_loss: 15420.8517\n",
      "Epoch 267/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19862.5230 - val_loss: 14701.4737\n",
      "Epoch 268/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19815.6728 - val_loss: 14743.0286\n",
      "Epoch 269/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19757.1898 - val_loss: 16036.5053\n",
      "Epoch 270/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19572.5032 - val_loss: 15336.2828\n",
      "Epoch 271/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19700.6566 - val_loss: 15040.9445\n",
      "Epoch 272/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19473.6894 - val_loss: 15602.6384\n",
      "Epoch 273/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19906.8170 - val_loss: 14509.2126\n",
      "Epoch 274/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19699.7736 - val_loss: 15772.0936\n",
      "Epoch 275/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 20105.0729 - val_loss: 14584.7437\n",
      "Epoch 276/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20147.8612 - val_loss: 15057.5087\n",
      "Epoch 277/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19881.5120 - val_loss: 18572.5668\n",
      "Epoch 278/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19517.4842 - val_loss: 16397.4856\n",
      "Epoch 279/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19976.7596 - val_loss: 15108.0453\n",
      "Epoch 280/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19935.8306 - val_loss: 15692.7591\n",
      "Epoch 281/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19793.6322 - val_loss: 14389.2686\n",
      "Epoch 282/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19412.6952 - val_loss: 15312.0001\n",
      "Epoch 283/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20059.2136 - val_loss: 15273.2969\n",
      "Epoch 284/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19604.2384 - val_loss: 14420.2558\n",
      "Epoch 285/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19496.6790 - val_loss: 14708.9673\n",
      "Epoch 286/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 20049.3460 - val_loss: 16034.7254\n",
      "Epoch 287/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 19478.0735 - val_loss: 14571.8502\n",
      "Epoch 288/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19667.3767 - val_loss: 14611.5370\n",
      "Epoch 289/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19504.3439 - val_loss: 14015.6003\n",
      "Epoch 290/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19758.8318 - val_loss: 16997.5221\n",
      "Epoch 291/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19601.7732 - val_loss: 17615.9217\n",
      "Epoch 292/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 19661.4567 - val_loss: 16816.5259\n",
      "Epoch 293/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19131.7665 - val_loss: 14086.0776\n",
      "Epoch 294/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19576.5483 - val_loss: 14701.9938\n",
      "Epoch 295/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 19444.5205 - val_loss: 14263.2803\n",
      "Epoch 296/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 19304.4485 - val_loss: 14911.7827\n",
      "Epoch 297/1000\n",
      "2304/2304 [==============================] - 2s 687us/step - loss: 19703.8128 - val_loss: 16053.4814\n",
      "Epoch 298/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 19346.9465 - val_loss: 14261.0299\n",
      "Epoch 299/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 19704.9612 - val_loss: 14267.3405\n",
      "Epoch 300/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19352.9026 - val_loss: 14148.4302\n",
      "Epoch 301/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19498.7444 - val_loss: 14138.5259\n",
      "Epoch 302/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18726.3407 - val_loss: 15887.5956\n",
      "Epoch 303/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19946.6447 - val_loss: 16257.2649\n",
      "Epoch 304/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 19362.7704 - val_loss: 13983.4914\n",
      "Epoch 305/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 18790.8474 - val_loss: 14023.9126\n",
      "Epoch 306/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19160.9730 - val_loss: 14827.6932\n",
      "Epoch 307/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19190.6534 - val_loss: 18906.2787\n",
      "Epoch 308/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19401.0639 - val_loss: 14333.4869\n",
      "Epoch 309/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19238.1993 - val_loss: 19174.5764\n",
      "Epoch 310/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20029.8387 - val_loss: 14179.8829\n",
      "Epoch 311/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18918.1769 - val_loss: 15346.9258\n",
      "Epoch 312/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19041.3360 - val_loss: 15424.8321\n",
      "Epoch 313/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19119.5293 - val_loss: 14270.7577\n",
      "Epoch 314/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19292.8256 - val_loss: 14625.2434\n",
      "Epoch 315/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19020.3923 - val_loss: 15541.8373\n",
      "Epoch 316/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19109.0529 - val_loss: 14618.3543\n",
      "Epoch 317/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18554.5315 - val_loss: 14239.7411\n",
      "Epoch 318/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19012.3046 - val_loss: 14200.9190\n",
      "Epoch 319/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18846.4739 - val_loss: 14101.2692\n",
      "Epoch 320/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18813.7599 - val_loss: 14046.8665\n",
      "Epoch 321/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18852.2364 - val_loss: 15203.3614\n",
      "Epoch 322/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19056.3984 - val_loss: 14890.5568\n",
      "Epoch 323/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 18563.3026 - val_loss: 13836.5927\n",
      "Epoch 324/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19340.7887 - val_loss: 14266.8893\n",
      "Epoch 325/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19060.3305 - val_loss: 15360.9089\n",
      "Epoch 326/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18662.2458 - val_loss: 14017.1838\n",
      "Epoch 327/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18428.4088 - val_loss: 14745.7661\n",
      "Epoch 328/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19135.0274 - val_loss: 15207.9820\n",
      "Epoch 329/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18923.7394 - val_loss: 14965.7481\n",
      "Epoch 330/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18535.9474 - val_loss: 17499.9861\n",
      "Epoch 331/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 19013.6725 - val_loss: 15235.5978\n",
      "Epoch 332/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 18596.5386 - val_loss: 15663.1766\n",
      "Epoch 333/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18753.9279 - val_loss: 14441.8432\n",
      "Epoch 334/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18830.9042 - val_loss: 14302.3303\n",
      "Epoch 335/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18712.8998 - val_loss: 14407.8947\n",
      "Epoch 336/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18339.9842 - val_loss: 16368.5578\n",
      "Epoch 337/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 18322.5995 - val_loss: 14554.7695\n",
      "Epoch 338/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18302.4392 - val_loss: 18285.9036\n",
      "Epoch 339/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 18712.5002 - val_loss: 16307.5702\n",
      "Epoch 340/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18290.9863 - val_loss: 14239.9206\n",
      "Epoch 341/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18704.4309 - val_loss: 14550.0324\n",
      "Epoch 342/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18247.0918 - val_loss: 14879.0659\n",
      "Epoch 343/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 18006.7334 - val_loss: 18404.3097\n",
      "Epoch 344/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18743.3766 - val_loss: 14351.7088\n",
      "Epoch 345/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18354.7083 - val_loss: 13809.4760\n",
      "Epoch 346/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18344.7377 - val_loss: 14164.0234\n",
      "Epoch 347/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17953.9372 - val_loss: 15203.0973\n",
      "Epoch 348/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18169.8337 - val_loss: 15557.0146\n",
      "Epoch 349/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 18846.4769 - val_loss: 13736.5097\n",
      "Epoch 350/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 18310.2781 - val_loss: 15919.4781\n",
      "Epoch 351/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17808.3110 - val_loss: 16368.7301\n",
      "Epoch 352/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18350.3996 - val_loss: 14352.2247\n",
      "Epoch 353/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 18125.6151 - val_loss: 14588.8044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17982.2255 - val_loss: 15111.4960\n",
      "Epoch 355/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18200.9428 - val_loss: 16779.2044\n",
      "Epoch 356/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17829.2466 - val_loss: 15074.7010\n",
      "Epoch 357/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 18016.9196 - val_loss: 14864.5632\n",
      "Epoch 358/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17915.1799 - val_loss: 24316.4935\n",
      "Epoch 359/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19223.4313 - val_loss: 14180.9230\n",
      "Epoch 360/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 18647.8201 - val_loss: 13863.6924\n",
      "Epoch 361/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 18664.2566 - val_loss: 15385.2874\n",
      "Epoch 362/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17911.7704 - val_loss: 14680.4609\n",
      "Epoch 363/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17927.6700 - val_loss: 14011.2587\n",
      "Epoch 364/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17879.9066 - val_loss: 14464.9448\n",
      "Epoch 365/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18198.5349 - val_loss: 15854.3383\n",
      "Epoch 366/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17806.2551 - val_loss: 16639.1137\n",
      "Epoch 367/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17713.9328 - val_loss: 15978.6447\n",
      "Epoch 368/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18191.1775 - val_loss: 13860.3972\n",
      "Epoch 369/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 17839.4774 - val_loss: 16243.3496\n",
      "Epoch 370/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18056.7944 - val_loss: 13988.9696\n",
      "Epoch 371/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17830.5053 - val_loss: 13991.4631\n",
      "Epoch 372/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17826.4593 - val_loss: 14288.8727\n",
      "Epoch 373/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18230.0502 - val_loss: 13970.4442\n",
      "Epoch 374/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18149.2701 - val_loss: 13912.5779\n",
      "Epoch 375/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17991.8544 - val_loss: 14408.1569\n",
      "Epoch 376/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17852.9588 - val_loss: 13976.1019\n",
      "Epoch 377/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17220.9854 - val_loss: 14601.7443\n",
      "Epoch 378/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18052.9831 - val_loss: 14810.8670\n",
      "Epoch 379/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17936.4085 - val_loss: 15385.9314\n",
      "Epoch 380/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17604.2571 - val_loss: 22286.7142\n",
      "Epoch 381/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18617.3345 - val_loss: 16034.6185\n",
      "Epoch 382/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17403.8869 - val_loss: 14999.4376\n",
      "Epoch 383/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17939.8127 - val_loss: 14766.4007\n",
      "Epoch 384/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18240.0339 - val_loss: 14057.3904\n",
      "Epoch 385/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 17869.7416 - val_loss: 17336.3759\n",
      "Epoch 386/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17826.6345 - val_loss: 15285.4909\n",
      "Epoch 387/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17667.2922 - val_loss: 14430.3984\n",
      "Epoch 388/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17571.7256 - val_loss: 14216.6904\n",
      "Epoch 389/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17352.5210 - val_loss: 13842.0403\n",
      "Epoch 390/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17804.1591 - val_loss: 14489.6196\n",
      "Epoch 391/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17290.5272 - val_loss: 15556.0982\n",
      "Epoch 392/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17562.2438 - val_loss: 14057.2289\n",
      "Epoch 393/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17475.4925 - val_loss: 14393.1716\n",
      "Epoch 394/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 17683.2711 - val_loss: 13867.6408\n",
      "Epoch 395/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18206.1145 - val_loss: 14119.2243\n",
      "Epoch 396/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17573.8009 - val_loss: 14654.6191\n",
      "Epoch 397/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17220.1603 - val_loss: 17501.2350\n",
      "Epoch 398/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17444.1953 - val_loss: 15443.5200\n",
      "Epoch 399/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17212.9262 - val_loss: 14271.1408\n",
      "Epoch 400/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18024.3335 - val_loss: 14294.3726\n",
      "Epoch 401/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17486.2469 - val_loss: 13969.2431\n",
      "Epoch 402/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17356.3129 - val_loss: 14932.2968\n",
      "Epoch 403/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17733.6313 - val_loss: 15349.2541\n",
      "Epoch 404/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17096.2496 - val_loss: 14960.6332\n",
      "Epoch 405/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17120.7252 - val_loss: 14787.6082\n",
      "Epoch 406/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17491.6736 - val_loss: 19178.5432\n",
      "Epoch 407/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17724.7867 - val_loss: 14122.0443\n",
      "Epoch 408/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17579.8739 - val_loss: 14003.0985\n",
      "Epoch 409/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17608.8391 - val_loss: 17843.3101\n",
      "Epoch 410/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17523.1099 - val_loss: 14959.4707\n",
      "Epoch 411/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16910.8874 - val_loss: 13747.2737\n",
      "Epoch 412/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17539.3152 - val_loss: 14720.9098\n",
      "Epoch 413/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17267.5506 - val_loss: 14258.4516\n",
      "Epoch 414/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17315.9268 - val_loss: 13593.2258\n",
      "Epoch 415/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17380.5531 - val_loss: 14079.7826\n",
      "Epoch 416/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16996.8228 - val_loss: 15113.6179\n",
      "Epoch 417/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17600.8175 - val_loss: 18986.0353\n",
      "Epoch 418/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17023.1818 - val_loss: 14341.5397\n",
      "Epoch 419/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17573.1886 - val_loss: 14370.9430\n",
      "Epoch 420/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17225.8739 - val_loss: 15407.3638\n",
      "Epoch 421/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17412.0493 - val_loss: 19036.0672\n",
      "Epoch 422/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17108.0607 - val_loss: 15606.9727\n",
      "Epoch 423/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17136.4948 - val_loss: 15391.9444\n",
      "Epoch 424/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17093.5108 - val_loss: 14448.2228\n",
      "Epoch 425/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16837.8037 - val_loss: 16118.2474\n",
      "Epoch 426/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17296.2004 - val_loss: 13944.9400\n",
      "Epoch 427/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17272.2626 - val_loss: 13772.1651\n",
      "Epoch 428/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17281.5558 - val_loss: 13642.4159\n",
      "Epoch 429/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17101.2987 - val_loss: 15898.3358\n",
      "Epoch 430/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16709.3143 - val_loss: 19334.2600\n",
      "Epoch 431/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 16868.6854 - val_loss: 16250.8959\n",
      "Epoch 432/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17385.3112 - val_loss: 13705.7346\n",
      "Epoch 433/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17247.9291 - val_loss: 14623.1077\n",
      "Epoch 434/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17188.4737 - val_loss: 13852.3366\n",
      "Epoch 435/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16656.4663 - val_loss: 14797.9058\n",
      "Epoch 436/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17156.8052 - val_loss: 13735.2475\n",
      "Epoch 437/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 17050.5127 - val_loss: 17040.0685\n",
      "Epoch 438/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16785.3803 - val_loss: 15292.6484\n",
      "Epoch 439/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16491.9697 - val_loss: 15786.6080\n",
      "Epoch 440/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17464.6337 - val_loss: 15852.0196\n",
      "Epoch 441/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17213.6505 - val_loss: 15082.6042\n",
      "Epoch 442/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17345.8611 - val_loss: 14912.8041\n",
      "Epoch 443/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16981.0900 - val_loss: 18065.5751\n",
      "Epoch 444/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17532.0109 - val_loss: 16386.4432\n",
      "Epoch 445/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17591.5213 - val_loss: 14487.9600\n",
      "Epoch 446/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17624.2621 - val_loss: 16752.8077\n",
      "Epoch 447/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16998.9168 - val_loss: 13496.9836\n",
      "Epoch 448/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 16836.7056 - val_loss: 14631.2539\n",
      "Epoch 449/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16696.3389 - val_loss: 16631.2494\n",
      "Epoch 450/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16983.9090 - val_loss: 15312.0523\n",
      "Epoch 451/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16810.2610 - val_loss: 14278.9533\n",
      "Epoch 452/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17404.3263 - val_loss: 15086.4043\n",
      "Epoch 453/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17100.2959 - val_loss: 13936.6329\n",
      "Epoch 454/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16667.1507 - val_loss: 18293.9448\n",
      "Epoch 455/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17168.9288- ETA: 0s - - 1s 438us/step - loss: 17086.7000 - val_loss: 13579.2260\n",
      "Epoch 456/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16701.5239 - val_loss: 14569.9128\n",
      "Epoch 457/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16879.7268 - val_loss: 13863.3398\n",
      "Epoch 458/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16426.4349 - val_loss: 17490.6424\n",
      "Epoch 459/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 17047.0664 - val_loss: 14906.5276\n",
      "Epoch 460/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17470.8861 - val_loss: 14052.3652\n",
      "Epoch 461/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16674.0154 - val_loss: 17727.5517\n",
      "Epoch 462/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17145.5984 - val_loss: 14692.3786\n",
      "Epoch 463/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17166.9755 - val_loss: 14124.9136\n",
      "Epoch 464/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16679.6169 - val_loss: 19373.4150\n",
      "Epoch 465/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16774.5541 - val_loss: 14200.0199\n",
      "Epoch 466/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16595.9005 - val_loss: 14423.6457\n",
      "Epoch 467/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16689.2204 - val_loss: 14240.4985\n",
      "Epoch 468/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16708.0954 - val_loss: 14334.9017\n",
      "Epoch 469/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17191.4972 - val_loss: 13775.6621\n",
      "Epoch 470/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17505.5673 - val_loss: 13765.9852\n",
      "Epoch 471/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 17377.3753 - val_loss: 16874.4895\n",
      "Epoch 472/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16932.0075 - val_loss: 15280.1072\n",
      "Epoch 473/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16530.4014 - val_loss: 14520.9200\n",
      "Epoch 474/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17395.5364 - val_loss: 13848.9501\n",
      "Epoch 475/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16857.5059 - val_loss: 13565.6380\n",
      "Epoch 476/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 16767.7075 - val_loss: 19872.7868\n",
      "Epoch 477/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16884.9123 - val_loss: 13176.7210\n",
      "Epoch 478/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16330.7191 - val_loss: 14813.3151\n",
      "Epoch 479/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 16560.1846 - val_loss: 13560.4959\n",
      "Epoch 480/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16994.8374 - val_loss: 13748.0220\n",
      "Epoch 481/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 17105.0768 - val_loss: 13977.5572\n",
      "Epoch 482/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 16926.7186 - val_loss: 15421.4735\n",
      "Epoch 483/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17416.383 - 1s 442us/step - loss: 17520.7117 - val_loss: 14974.8713\n",
      "Epoch 484/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17241.7099 - val_loss: 16109.2987\n",
      "Epoch 485/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 16878.6128 - val_loss: 13340.2037\n",
      "Epoch 486/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 16567.2597 - val_loss: 13226.7989\n",
      "Epoch 487/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17009.0485 - val_loss: 14334.8273\n",
      "Epoch 488/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17224.3196 - val_loss: 15182.8221\n",
      "Epoch 489/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16113.3428 - val_loss: 14707.3002\n",
      "Epoch 490/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16157.4614 - val_loss: 17262.7748\n",
      "Epoch 491/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16754.3682 - val_loss: 17514.4146\n",
      "Epoch 492/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16435.4573 - val_loss: 13711.0666\n",
      "Epoch 493/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17039.9159 - val_loss: 15920.7148\n",
      "Epoch 494/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 443us/step - loss: 16618.5890 - val_loss: 13543.7893\n",
      "Epoch 495/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17146.2448 - val_loss: 18693.5495\n",
      "Epoch 496/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16916.5060 - val_loss: 13491.6188\n",
      "Epoch 497/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16322.7569 - val_loss: 14055.7516\n",
      "Epoch 498/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16738.7356 - val_loss: 13729.1235\n",
      "Epoch 499/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17037.1458 - val_loss: 19032.3017\n",
      "Epoch 500/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17037.1399 - val_loss: 13309.6670\n",
      "Epoch 501/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16405.3647 - val_loss: 13464.1638\n",
      "Epoch 502/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17211.2725 - val_loss: 17083.4213\n",
      "Epoch 503/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17172.4802 - val_loss: 13478.5523\n",
      "Epoch 504/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16247.5303 - val_loss: 14198.8873\n",
      "Epoch 505/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16671.5918 - val_loss: 13535.8521\n",
      "Epoch 506/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16185.6086 - val_loss: 14095.6265\n",
      "Epoch 507/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16207.7347 - val_loss: 14325.4418\n",
      "Epoch 508/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16652.1647 - val_loss: 14851.3673\n",
      "Epoch 509/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 16606.8829 - val_loss: 14483.6561\n",
      "Epoch 510/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16154.6917 - val_loss: 13027.8321\n",
      "Epoch 511/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 16352.7531 - val_loss: 13074.6578\n",
      "Epoch 512/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16269.5398 - val_loss: 15614.6946\n",
      "Epoch 513/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16844.1695 - val_loss: 13532.4958\n",
      "Epoch 514/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16391.5720 - val_loss: 13839.0900\n",
      "Epoch 515/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16910.4774 - val_loss: 13006.5320\n",
      "Epoch 516/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16441.9044 - val_loss: 13741.3823\n",
      "Epoch 517/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16175.2031 - val_loss: 13118.6830\n",
      "Epoch 518/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16029.5415 - val_loss: 13535.7123\n",
      "Epoch 519/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16822.5800 - val_loss: 12918.1999\n",
      "Epoch 520/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16400.1417 - val_loss: 13436.6186\n",
      "Epoch 521/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 16581.6498 - val_loss: 13149.8857\n",
      "Epoch 522/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16398.8991 - val_loss: 13370.1782\n",
      "Epoch 523/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16296.1482 - val_loss: 16340.5884\n",
      "Epoch 524/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16327.9647 - val_loss: 13298.2406\n",
      "Epoch 525/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16280.1426 - val_loss: 13291.0479\n",
      "Epoch 526/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16098.8848 - val_loss: 13626.7445\n",
      "Epoch 527/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16265.7438 - val_loss: 13826.5380\n",
      "Epoch 528/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15989.9011 - val_loss: 14713.3395\n",
      "Epoch 529/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15569.1148 - val_loss: 13209.5831\n",
      "Epoch 530/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16541.1532 - val_loss: 17341.2461\n",
      "Epoch 531/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16239.2389 - val_loss: 13829.2114\n",
      "Epoch 532/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16521.4224 - val_loss: 15856.1819\n",
      "Epoch 533/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15968.5748 - val_loss: 12955.7784\n",
      "Epoch 534/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16293.7703 - val_loss: 13159.6920\n",
      "Epoch 535/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15915.4719 - val_loss: 15236.5337\n",
      "Epoch 536/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16546.5183 - val_loss: 16853.1425\n",
      "Epoch 537/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16415.3709 - val_loss: 22590.1958\n",
      "Epoch 538/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16038.1731 - val_loss: 15478.0320\n",
      "Epoch 539/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16662.2867 - val_loss: 13633.4050\n",
      "Epoch 540/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16813.9251 - val_loss: 12660.4432\n",
      "Epoch 541/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16527.9992 - val_loss: 14913.9604\n",
      "Epoch 542/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 16079.3291 - val_loss: 13788.1918\n",
      "Epoch 543/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16225.2902 - val_loss: 14426.3797\n",
      "Epoch 544/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15732.6024 - val_loss: 13636.5850\n",
      "Epoch 545/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16214.2543 - val_loss: 21259.3888\n",
      "Epoch 546/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16336.5275 - val_loss: 13642.9841\n",
      "Epoch 547/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16242.7494 - val_loss: 12891.3443\n",
      "Epoch 548/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15609.3064 - val_loss: 15241.3289\n",
      "Epoch 549/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 16055.6001 - val_loss: 15129.6870\n",
      "Epoch 550/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 16056.1482 - val_loss: 13194.1173\n",
      "Epoch 551/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16373.1419 - val_loss: 13835.9007\n",
      "Epoch 552/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 16585.9757 - val_loss: 15642.5804\n",
      "Epoch 553/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16268.6899 - val_loss: 12619.5854\n",
      "Epoch 554/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16432.3227 - val_loss: 14910.7167\n",
      "Epoch 555/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15964.3666 - val_loss: 13346.9381\n",
      "Epoch 556/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15907.5030 - val_loss: 12983.0486\n",
      "Epoch 557/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15918.8584 - val_loss: 13650.5844\n",
      "Epoch 558/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16200.4612 - val_loss: 12951.2539\n",
      "Epoch 559/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15835.6661 - val_loss: 14813.2323\n",
      "Epoch 560/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16570.0578 - val_loss: 14454.0631\n",
      "Epoch 561/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16869.6169 - val_loss: 13610.7718\n",
      "Epoch 562/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16840.4261 - val_loss: 13181.9136\n",
      "Epoch 563/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15979.8033 - val_loss: 13446.4118\n",
      "Epoch 564/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15563.6671 - val_loss: 13199.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15908.4225 - val_loss: 15984.1726\n",
      "Epoch 566/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16004.9399 - val_loss: 13905.7834\n",
      "Epoch 567/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16389.2974 - val_loss: 13452.7645\n",
      "Epoch 568/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15584.9971 - val_loss: 14775.5267\n",
      "Epoch 569/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15664.2811 - val_loss: 13648.0294\n",
      "Epoch 570/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16375.2549 - val_loss: 13240.0203\n",
      "Epoch 571/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15903.5278 - val_loss: 14575.3229\n",
      "Epoch 572/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16540.2915 - val_loss: 12986.2193\n",
      "Epoch 573/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15546.8738 - val_loss: 12724.5387\n",
      "Epoch 574/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15573.6981 - val_loss: 14370.9492\n",
      "Epoch 575/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15998.9777 - val_loss: 14381.9216\n",
      "Epoch 576/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16236.6067 - val_loss: 13139.3926\n",
      "Epoch 577/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16401.3169 - val_loss: 12909.4291\n",
      "Epoch 578/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15951.6085 - val_loss: 13372.4539\n",
      "Epoch 579/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15390.301 - 1s 447us/step - loss: 15447.2109 - val_loss: 16080.7027\n",
      "Epoch 580/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15932.6666 - val_loss: 13824.2292\n",
      "Epoch 581/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15664.1162 - val_loss: 14778.0713\n",
      "Epoch 582/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15933.7029 - val_loss: 13003.9517\n",
      "Epoch 583/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15956.3189 - val_loss: 16177.6614\n",
      "Epoch 584/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15874.3583 - val_loss: 13080.2921\n",
      "Epoch 585/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16791.4277 - val_loss: 14088.6852\n",
      "Epoch 586/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15705.0799 - val_loss: 18454.0310\n",
      "Epoch 587/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15808.1309 - val_loss: 16820.5833\n",
      "Epoch 588/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16183.8922 - val_loss: 14711.2256\n",
      "Epoch 589/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15707.8248 - val_loss: 13111.5689\n",
      "Epoch 590/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16598.3475 - val_loss: 15295.8216\n",
      "Epoch 591/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15327.5790 - val_loss: 13901.1989\n",
      "Epoch 592/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15704.7646 - val_loss: 13032.4837\n",
      "Epoch 593/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15951.6286 - val_loss: 13004.5162\n",
      "Epoch 594/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15690.0711 - val_loss: 12766.9858\n",
      "Epoch 595/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15764.8322 - val_loss: 14098.1799\n",
      "Epoch 596/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16039.9761 - val_loss: 14123.3657\n",
      "Epoch 597/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16197.0552 - val_loss: 13257.4783\n",
      "Epoch 598/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15653.8917 - val_loss: 13044.1128\n",
      "Epoch 599/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 16027.9724 - val_loss: 14400.0111\n",
      "Epoch 600/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 15569.4053 - val_loss: 14585.1445\n",
      "Epoch 601/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16236.5629 - val_loss: 14213.7991\n",
      "Epoch 602/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15410.8726 - val_loss: 13744.9428\n",
      "Epoch 603/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15623.0107 - val_loss: 13769.4555\n",
      "Epoch 604/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15422.4580 - val_loss: 13720.9273\n",
      "Epoch 605/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15629.3536 - val_loss: 13780.4440\n",
      "Epoch 606/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15512.328 - 1s 449us/step - loss: 15667.5894 - val_loss: 15107.2038\n",
      "Epoch 607/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15842.8541 - val_loss: 15396.6564\n",
      "Epoch 608/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16343.3226 - val_loss: 16418.3831\n",
      "Epoch 609/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15627.2895 - val_loss: 13080.5057\n",
      "Epoch 610/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 16138.2899 - val_loss: 13839.8605\n",
      "Epoch 611/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15795.7646 - val_loss: 14323.5030\n",
      "Epoch 612/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16000.4406 - val_loss: 14379.4820\n",
      "Epoch 613/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15908.1178 - val_loss: 12850.5682\n",
      "Epoch 614/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16145.5608 - val_loss: 13584.1879\n",
      "Epoch 615/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15431.5824 - val_loss: 13392.1331\n",
      "Epoch 616/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16703.4658 - val_loss: 14792.3624\n",
      "Epoch 617/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15772.0554 - val_loss: 15436.8464\n",
      "Epoch 618/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15374.9280 - val_loss: 13229.2396\n",
      "Epoch 619/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15145.3295 - val_loss: 14809.5443\n",
      "Epoch 620/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15543.2908 - val_loss: 16547.6276\n",
      "Epoch 621/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15959.9643 - val_loss: 16376.9515\n",
      "Epoch 622/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15781.9054 - val_loss: 15017.2809\n",
      "Epoch 623/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15574.1608 - val_loss: 12977.8039\n",
      "Epoch 624/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15664.0746 - val_loss: 16512.8301\n",
      "Epoch 625/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15434.6600 - val_loss: 13110.2442\n",
      "Epoch 626/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15833.0265 - val_loss: 13771.7392\n",
      "Epoch 627/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15141.2832 - val_loss: 12895.8720\n",
      "Epoch 628/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15806.2560 - val_loss: 12599.8844\n",
      "Epoch 629/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15253.5951 - val_loss: 15702.9138\n",
      "Epoch 630/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 16220.005 - 1s 446us/step - loss: 16211.7160 - val_loss: 13587.7423\n",
      "Epoch 631/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15374.0106 - val_loss: 16109.5302\n",
      "Epoch 632/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15973.8315 - val_loss: 14559.4370\n",
      "Epoch 633/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15757.8239 - val_loss: 14605.0098\n",
      "Epoch 634/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15382.4610 - val_loss: 15446.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15981.6069 - val_loss: 14574.5966\n",
      "Epoch 636/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15255.1359 - val_loss: 16051.3238\n",
      "Epoch 637/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15448.6940 - val_loss: 13010.1859\n",
      "Epoch 638/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15537.2544 - val_loss: 14263.5028\n",
      "Epoch 639/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15717.0864 - val_loss: 13682.7131\n",
      "Epoch 640/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15358.8598 - val_loss: 13410.3975\n",
      "Epoch 641/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15642.4729 - val_loss: 13778.9329\n",
      "Epoch 642/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16350.4903 - val_loss: 21586.3186\n",
      "Epoch 643/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15697.2444 - val_loss: 13705.7611\n",
      "Epoch 644/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15046.5153 - val_loss: 16719.6757\n",
      "Epoch 645/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15784.5210 - val_loss: 13796.9106\n",
      "Epoch 646/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15669.4205 - val_loss: 12644.5263\n",
      "Epoch 647/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15642.5598 - val_loss: 13163.1053\n",
      "Epoch 648/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15469.4455 - val_loss: 14157.4993\n",
      "Epoch 649/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15148.3762 - val_loss: 12870.2361\n",
      "Epoch 650/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15614.2960 - val_loss: 12830.4788\n",
      "Epoch 651/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15455.5890 - val_loss: 14309.9376\n",
      "Epoch 652/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15504.0487 - val_loss: 12620.4909\n",
      "Epoch 653/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15521.0770 - val_loss: 13617.4397\n",
      "Epoch 654/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15487.8799 - val_loss: 13259.1685\n",
      "Epoch 655/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15204.8147 - val_loss: 13958.5722\n",
      "Epoch 656/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15702.2916 - val_loss: 13165.9372\n",
      "Epoch 657/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15200.5446 - val_loss: 14146.9903\n",
      "Epoch 658/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 15479.8287 - val_loss: 13355.3974\n",
      "Epoch 659/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15440.6843 - val_loss: 13331.1294\n",
      "Epoch 660/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15174.4019 - val_loss: 12858.8573\n",
      "Epoch 661/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15110.9219 - val_loss: 12799.9921\n",
      "Epoch 662/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15598.324 - 1s 448us/step - loss: 15515.2419 - val_loss: 12942.6975\n",
      "Epoch 663/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16275.1000 - val_loss: 16717.4047\n",
      "Epoch 664/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16169.6125 - val_loss: 12684.8459\n",
      "Epoch 665/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15119.5771 - val_loss: 17778.7259\n",
      "Epoch 666/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15477.4023 - val_loss: 13685.2982\n",
      "Epoch 667/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15982.5753 - val_loss: 14503.3253\n",
      "Epoch 668/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15682.8486 - val_loss: 15272.2460\n",
      "Epoch 669/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15223.0342 - val_loss: 12861.6631\n",
      "Epoch 670/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 15199.3037 - val_loss: 12720.9584\n",
      "Epoch 671/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15367.5364 - val_loss: 12661.7466\n",
      "Epoch 672/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15171.9637 - val_loss: 13398.3861\n",
      "Epoch 673/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15272.5848 - val_loss: 13891.8174\n",
      "Epoch 674/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15364.4168 - val_loss: 13129.6698\n",
      "Epoch 675/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15352.5513 - val_loss: 13137.0173\n",
      "Epoch 676/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15420.8494 - val_loss: 14306.8728\n",
      "Epoch 677/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15816.9606 - val_loss: 13225.2205\n",
      "Epoch 678/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15520.9441 - val_loss: 12961.2857\n",
      "Epoch 679/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16166.1388 - val_loss: 13093.5504\n",
      "Epoch 680/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15809.7020 - val_loss: 12755.8231\n",
      "Epoch 681/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15275.4096 - val_loss: 14574.4372\n",
      "Epoch 682/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15262.1467 - val_loss: 15008.6220\n",
      "Epoch 683/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15541.8515 - val_loss: 12507.0198\n",
      "Epoch 684/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15458.2967 - val_loss: 12919.8445\n",
      "Epoch 685/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15089.8102 - val_loss: 13483.9403\n",
      "Epoch 686/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15078.7916 - val_loss: 13308.9251\n",
      "Epoch 687/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14969.1277 - val_loss: 15465.7025\n",
      "Epoch 688/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15335.7592 - val_loss: 12952.5697\n",
      "Epoch 689/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15527.9751 - val_loss: 17052.4783\n",
      "Epoch 690/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15339.5878 - val_loss: 14415.3618\n",
      "Epoch 691/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15469.8665 - val_loss: 14247.9914\n",
      "Epoch 692/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15702.3830 - val_loss: 17907.0751\n",
      "Epoch 693/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15765.4085 - val_loss: 13254.7512\n",
      "Epoch 694/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15332.0656 - val_loss: 18456.6299\n",
      "Epoch 695/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15447.8551 - val_loss: 12613.2257\n",
      "Epoch 696/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14687.8422 - val_loss: 13083.2457\n",
      "Epoch 697/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15330.3883 - val_loss: 18014.6404\n",
      "Epoch 698/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15781.9598 - val_loss: 16162.5326\n",
      "Epoch 699/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15493.8309 - val_loss: 17285.5977\n",
      "Epoch 700/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15423.0763 - val_loss: 12625.9207\n",
      "Epoch 701/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15297.0811 - val_loss: 13373.4003\n",
      "Epoch 702/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15426.0078 - val_loss: 13488.4394\n",
      "Epoch 703/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15466.9557 - val_loss: 14845.1572\n",
      "Epoch 704/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15065.8811 - val_loss: 12732.2395\n",
      "Epoch 705/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15026.7516 - val_loss: 13223.4333\n",
      "Epoch 706/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15230.2854 - val_loss: 14756.2749\n",
      "Epoch 707/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15406.9381 - val_loss: 13308.5025\n",
      "Epoch 708/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15260.3629 - val_loss: 18116.0258\n",
      "Epoch 709/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15283.3038 - val_loss: 13337.3922\n",
      "Epoch 710/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15137.5314 - val_loss: 13265.3038\n",
      "Epoch 711/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15759.4561 - val_loss: 14528.8233\n",
      "Epoch 712/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15241.5850 - val_loss: 12762.3783\n",
      "Epoch 713/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14968.4679 - val_loss: 13901.8424\n",
      "Epoch 714/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15471.8470 - val_loss: 13121.6925\n",
      "Epoch 715/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15340.8782 - val_loss: 16421.3447\n",
      "Epoch 716/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15203.0577 - val_loss: 13425.4123\n",
      "Epoch 717/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15364.1613 - val_loss: 14678.5288\n",
      "Epoch 718/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15190.8276 - val_loss: 13293.1317\n",
      "Epoch 719/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15485.2657 - val_loss: 16684.7799\n",
      "Epoch 720/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16062.7201 - val_loss: 12756.5438\n",
      "Epoch 721/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15582.1366 - val_loss: 13934.6589\n",
      "Epoch 722/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14930.4560 - val_loss: 14532.9120\n",
      "Epoch 723/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15068.7575 - val_loss: 12634.7672\n",
      "Epoch 724/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15363.4014 - val_loss: 13434.6976\n",
      "Epoch 725/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15257.4327 - val_loss: 18779.9918\n",
      "Epoch 726/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15877.7786 - val_loss: 13005.0797\n",
      "Epoch 727/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15261.8529 - val_loss: 12943.7489\n",
      "Epoch 728/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15631.8654 - val_loss: 12685.7935\n",
      "Epoch 729/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15082.9631 - val_loss: 12853.9259\n",
      "Epoch 730/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14789.6620 - val_loss: 13291.1079\n",
      "Epoch 731/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14779.1322 - val_loss: 12923.7221\n",
      "Epoch 732/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14957.5461 - val_loss: 14639.1517\n",
      "Epoch 733/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15424.5130 - val_loss: 12906.5334\n",
      "Epoch 734/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15092.7149 - val_loss: 12938.7308\n",
      "Epoch 735/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14993.9403 - val_loss: 13545.9049\n",
      "Epoch 736/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14567.7017 - val_loss: 13553.1889\n",
      "Epoch 737/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 15193.0467 - val_loss: 16555.1944\n",
      "Epoch 738/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15208.2199 - val_loss: 13473.8713\n",
      "Epoch 739/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15558.0719 - val_loss: 13306.9156\n",
      "Epoch 740/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15205.8590 - val_loss: 13603.1274\n",
      "Epoch 741/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14711.1822 - val_loss: 17975.5598\n",
      "Epoch 742/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15439.0352 - val_loss: 18252.7317\n",
      "Epoch 743/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14858.0257 - val_loss: 13080.7335\n",
      "Epoch 744/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15334.4735 - val_loss: 12367.6314\n",
      "Epoch 745/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15592.4208 - val_loss: 12456.6742\n",
      "Epoch 746/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15372.3296 - val_loss: 13681.8867\n",
      "Epoch 747/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15552.5056 - val_loss: 13359.9924\n",
      "Epoch 748/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15025.2245 - val_loss: 13198.7190\n",
      "Epoch 749/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15587.6711 - val_loss: 13291.3897\n",
      "Epoch 750/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15234.3599 - val_loss: 13104.8654\n",
      "Epoch 751/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15286.4515 - val_loss: 13389.0263\n",
      "Epoch 752/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15011.1919 - val_loss: 13671.0663\n",
      "Epoch 753/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14678.4676 - val_loss: 13171.7875\n",
      "Epoch 754/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14898.6622 - val_loss: 16745.6186\n",
      "Epoch 755/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14864.0150 - val_loss: 14502.9875\n",
      "Epoch 756/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14996.6706 - val_loss: 14170.1225\n",
      "Epoch 757/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14958.4556 - val_loss: 13103.1940\n",
      "Epoch 758/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14827.0645 - val_loss: 12728.4479\n",
      "Epoch 759/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15163.0861 - val_loss: 13287.7952\n",
      "Epoch 760/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14740.0526 - val_loss: 12897.9880\n",
      "Epoch 761/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14966.5553 - val_loss: 13621.3832\n",
      "Epoch 762/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14799.1578 - val_loss: 14286.3744\n",
      "Epoch 763/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14436.9415 - val_loss: 13498.1127\n",
      "Epoch 764/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15144.7726 - val_loss: 12865.2890\n",
      "Epoch 765/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15369.3907 - val_loss: 13159.7846\n",
      "Epoch 766/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14932.8306 - val_loss: 13319.9050\n",
      "Epoch 767/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14700.5915 - val_loss: 12496.0247\n",
      "Epoch 768/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14422.4766 - val_loss: 12903.3622\n",
      "Epoch 769/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 14772.8422 - val_loss: 12729.0690\n",
      "Epoch 770/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15411.607 - 1s 442us/step - loss: 15346.0232 - val_loss: 14042.6256\n",
      "Epoch 771/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15231.9011 - val_loss: 13969.7030\n",
      "Epoch 772/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15155.9134 - val_loss: 14454.8772\n",
      "Epoch 773/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15267.4308 - val_loss: 13259.2004\n",
      "Epoch 774/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14596.1594 - val_loss: 13166.8524\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 420us/step - loss: 14974.0176 - val_loss: 15539.5823\n",
      "Epoch 776/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15169.9119 - val_loss: 13228.7943\n",
      "Epoch 777/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14630.1758 - val_loss: 13663.6288\n",
      "Epoch 778/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14674.2638 - val_loss: 12558.5938\n",
      "Epoch 779/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14920.9787 - val_loss: 13532.3238\n",
      "Epoch 780/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 15182.5596 - val_loss: 15951.0021\n",
      "Epoch 781/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14665.4194 - val_loss: 12908.2029\n",
      "Epoch 782/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14690.0533 - val_loss: 14167.9302\n",
      "Epoch 783/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14653.5695 - val_loss: 17030.5262\n",
      "Epoch 784/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15122.4909 - val_loss: 12568.5641\n",
      "Epoch 785/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15265.6583 - val_loss: 12658.0560\n",
      "Epoch 786/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 14948.2878 - val_loss: 13892.8752\n",
      "Epoch 787/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14933.4436 - val_loss: 14457.1670\n",
      "Epoch 788/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15085.2040 - val_loss: 13747.4289\n",
      "Epoch 789/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15379.0492 - val_loss: 19403.6576\n",
      "Epoch 790/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 15351.0965 - val_loss: 15456.3321\n",
      "Epoch 791/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14805.4371 - val_loss: 12852.0827\n",
      "Epoch 792/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14794.1490 - val_loss: 12984.7817\n",
      "Epoch 793/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14434.4702 - val_loss: 12845.6965\n",
      "Epoch 794/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 14672.0893 - val_loss: 13594.8156\n",
      "Epoch 795/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 14665.5351 - val_loss: 13367.0068\n",
      "Epoch 796/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14691.3304 - val_loss: 12902.3428\n",
      "Epoch 797/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15322.3794 - val_loss: 13206.3453\n",
      "Epoch 798/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14591.8013 - val_loss: 12691.5457\n",
      "Epoch 799/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14238.9320 - val_loss: 12883.0565\n",
      "Epoch 800/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14562.4019 - val_loss: 13239.7346\n",
      "Epoch 801/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14895.1009 - val_loss: 12925.1134\n",
      "Epoch 802/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14640.8927 - val_loss: 12759.0829\n",
      "Epoch 803/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14646.1457 - val_loss: 12718.9311\n",
      "Epoch 804/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14635.7928 - val_loss: 12636.7899\n",
      "Epoch 805/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 13996.3517 - val_loss: 14381.3851\n",
      "Epoch 806/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14318.8125 - val_loss: 15468.8791\n",
      "Epoch 807/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14880.0421 - val_loss: 13126.8431\n",
      "Epoch 808/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15080.8034 - val_loss: 14136.3962\n",
      "Epoch 809/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15469.5417 - val_loss: 12694.9700\n",
      "Epoch 810/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14256.0116 - val_loss: 12779.1585\n",
      "Epoch 811/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15062.1193 - val_loss: 13845.3082\n",
      "Epoch 812/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14080.0018 - val_loss: 13449.0193\n",
      "Epoch 813/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14612.0249 - val_loss: 13226.6961\n",
      "Epoch 814/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14793.5876 - val_loss: 12672.4397\n",
      "Epoch 815/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14473.2528 - val_loss: 12693.7991\n",
      "Epoch 816/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14533.8183 - val_loss: 13692.2471\n",
      "Epoch 817/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14729.4543 - val_loss: 13083.3531\n",
      "Epoch 818/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14497.7936 - val_loss: 13903.4400\n",
      "Epoch 819/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14109.7411 - val_loss: 13386.7339\n",
      "Epoch 820/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14994.6687 - val_loss: 14384.5567\n",
      "Epoch 821/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14667.1439 - val_loss: 16717.5792\n",
      "Epoch 822/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 15194.1799 - val_loss: 12673.5339\n",
      "Epoch 823/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14383.1840 - val_loss: 13179.6093\n",
      "Epoch 824/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14762.0785 - val_loss: 12920.0712\n",
      "Epoch 825/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14621.4354 - val_loss: 13191.5815\n",
      "Epoch 826/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14784.9669 - val_loss: 12863.7764\n",
      "Epoch 827/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14490.9969 - val_loss: 12752.3748\n",
      "Epoch 828/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14351.1834 - val_loss: 12576.6446\n",
      "Epoch 829/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 15036.8720 - val_loss: 12418.5804\n",
      "Epoch 830/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14464.0178 - val_loss: 12871.3090\n",
      "Epoch 831/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14654.7483 - val_loss: 13201.5221\n",
      "Epoch 832/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14462.2237 - val_loss: 13925.0163\n",
      "Epoch 833/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14949.5650 - val_loss: 13039.8272\n",
      "Epoch 834/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14270.4275 - val_loss: 12572.5281\n",
      "Epoch 835/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14900.3856 - val_loss: 12620.9649\n",
      "Epoch 836/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14709.6670 - val_loss: 12989.1388\n",
      "Epoch 837/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14657.4319 - val_loss: 13228.2369\n",
      "Epoch 838/1000\n",
      "2304/2304 [==============================] - 1s 472us/step - loss: 14724.9100 - val_loss: 12757.6617\n",
      "Epoch 839/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14601.4974 - val_loss: 12417.1430\n",
      "Epoch 840/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14986.3101 - val_loss: 17222.0426\n",
      "Epoch 841/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 15089.0709 - val_loss: 12555.9500\n",
      "Epoch 842/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14993.7458 - val_loss: 14066.9829\n",
      "Epoch 843/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14532.6220 - val_loss: 18880.1531\n",
      "Epoch 844/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14584.9105 - val_loss: 13635.9832\n",
      "Epoch 845/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14396.5144 - val_loss: 12778.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14060.4311 - val_loss: 13225.5006\n",
      "Epoch 847/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14654.3758 - val_loss: 13023.3650\n",
      "Epoch 848/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14654.8375 - val_loss: 13103.5657\n",
      "Epoch 849/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14830.6239 - val_loss: 13058.2414\n",
      "Epoch 850/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14764.2105 - val_loss: 13815.4281\n",
      "Epoch 851/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14613.9552 - val_loss: 13237.9735\n",
      "Epoch 852/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14611.7756 - val_loss: 13520.5362\n",
      "Epoch 853/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14431.8364 - val_loss: 13894.3668\n",
      "Epoch 854/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15137.1521 - val_loss: 22284.5248\n",
      "Epoch 855/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14813.4715 - val_loss: 13260.7255\n",
      "Epoch 856/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14475.8784 - val_loss: 13210.7836\n",
      "Epoch 857/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 14933.4577 - val_loss: 12749.1952\n",
      "Epoch 858/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14291.2518 - val_loss: 14971.0328\n",
      "Epoch 859/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15208.3715 - val_loss: 15258.7614\n",
      "Epoch 860/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14987.8951 - val_loss: 13586.2548\n",
      "Epoch 861/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14492.0720 - val_loss: 17675.6073\n",
      "Epoch 862/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14506.5116 - val_loss: 12518.2817\n",
      "Epoch 863/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14188.5038 - val_loss: 13342.0729\n",
      "Epoch 864/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15359.8370 - val_loss: 16495.8379\n",
      "Epoch 865/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14965.1403 - val_loss: 13083.3793\n",
      "Epoch 866/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14175.7473 - val_loss: 13919.3206\n",
      "Epoch 867/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14389.9764 - val_loss: 13285.3221\n",
      "Epoch 868/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14221.4755 - val_loss: 16674.3418\n",
      "Epoch 869/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 13982.3276 - val_loss: 14725.3013\n",
      "Epoch 870/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14150.5493 - val_loss: 12991.6504\n",
      "Epoch 871/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14241.1971 - val_loss: 14242.6713\n",
      "Epoch 872/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14235.1650 - val_loss: 13106.2846\n",
      "Epoch 873/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14888.9844 - val_loss: 13805.2642\n",
      "Epoch 874/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 14627.0407 - val_loss: 13571.2920\n",
      "Epoch 875/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14100.9699 - val_loss: 13488.7944\n",
      "Epoch 876/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14497.7654 - val_loss: 12479.8602\n",
      "Epoch 877/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14594.8237 - val_loss: 12449.0825\n",
      "Epoch 878/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14203.2660 - val_loss: 12609.4652\n",
      "Epoch 879/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14727.8350 - val_loss: 12740.9682\n",
      "Epoch 880/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14200.1342 - val_loss: 12994.0223\n",
      "Epoch 881/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14441.8817 - val_loss: 16508.9571\n",
      "Epoch 882/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 14590.5564 - val_loss: 12704.1016\n",
      "Epoch 883/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14141.6053 - val_loss: 14625.2396\n",
      "Epoch 884/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14457.2792 - val_loss: 13181.9282\n",
      "Epoch 885/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 14154.0893 - val_loss: 13142.0646\n",
      "Epoch 886/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14099.0075 - val_loss: 12615.8368\n",
      "Epoch 887/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14432.0832 - val_loss: 13688.7647\n",
      "Epoch 888/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14763.6511 - val_loss: 12546.1383\n",
      "Epoch 889/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 14257.1427 - val_loss: 15314.1020\n",
      "Epoch 890/1000\n",
      "2304/2304 [==============================] - 1s 407us/step - loss: 14685.3420 - val_loss: 12802.6904\n",
      "Epoch 891/1000\n",
      "2304/2304 [==============================] - 1s 398us/step - loss: 14311.2269 - val_loss: 13009.1204\n",
      "Epoch 892/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14441.2347 - val_loss: 13246.5764\n",
      "Epoch 893/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 13962.6542 - val_loss: 13388.3987\n",
      "Epoch 894/1000\n",
      "2304/2304 [==============================] - 1s 403us/step - loss: 14644.0992 - val_loss: 16022.9132\n",
      "Epoch 895/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14487.1708 - val_loss: 13156.4069\n",
      "Epoch 896/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14494.2526 - val_loss: 12960.4321\n",
      "Epoch 897/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14206.2011 - val_loss: 13049.3552\n",
      "Epoch 898/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14461.0843 - val_loss: 13081.9360\n",
      "Epoch 899/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14231.0203 - val_loss: 12909.8227\n",
      "Epoch 900/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14248.6927 - val_loss: 15215.5780\n",
      "Epoch 901/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14475.0888 - val_loss: 12317.9968\n",
      "Epoch 902/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14409.6735 - val_loss: 12467.8517\n",
      "Epoch 903/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14274.7537 - val_loss: 13747.5079\n",
      "Epoch 904/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14452.9215 - val_loss: 12402.7182\n",
      "Epoch 905/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14406.0842 - val_loss: 13519.5157\n",
      "Epoch 906/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14147.5470 - val_loss: 15100.2449\n",
      "Epoch 907/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14430.0315 - val_loss: 13061.8966\n",
      "Epoch 908/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14037.1031 - val_loss: 15047.8518\n",
      "Epoch 909/1000\n",
      "2304/2304 [==============================] - 1s 404us/step - loss: 14497.5600 - val_loss: 12198.8537\n",
      "Epoch 910/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 14366.8323 - val_loss: 14644.8727\n",
      "Epoch 911/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14138.7617 - val_loss: 13198.3730\n",
      "Epoch 912/1000\n",
      "2304/2304 [==============================] - 1s 387us/step - loss: 14551.6633 - val_loss: 12640.6007\n",
      "Epoch 913/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 13842.8162 - val_loss: 13103.7514\n",
      "Epoch 914/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14027.096 - 1s 406us/step - loss: 14014.5653 - val_loss: 13519.0226\n",
      "Epoch 915/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14198.5005 - val_loss: 13368.7286\n",
      "Epoch 916/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14822.5560 - val_loss: 15374.5320\n",
      "Epoch 917/1000\n",
      "2304/2304 [==============================] - 1s 402us/step - loss: 14289.0921 - val_loss: 14090.4929\n",
      "Epoch 918/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 14206.7270 - val_loss: 13044.4802\n",
      "Epoch 919/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14460.7795 - val_loss: 13302.6180\n",
      "Epoch 920/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14155.9907 - val_loss: 13949.3602\n",
      "Epoch 921/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14249.6631 - val_loss: 13610.0707\n",
      "Epoch 922/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 13840.5041 - val_loss: 13909.9199\n",
      "Epoch 923/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 13814.5286 - val_loss: 12826.1274\n",
      "Epoch 924/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14904.2527 - val_loss: 13254.0662\n",
      "Epoch 925/1000\n",
      "2304/2304 [==============================] - 1s 401us/step - loss: 14411.9720 - val_loss: 12841.3170\n",
      "Epoch 926/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14629.6957 - val_loss: 15033.8485\n",
      "Epoch 927/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14348.2908 - val_loss: 14876.2320\n",
      "Epoch 928/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14075.3151 - val_loss: 13959.1821\n",
      "Epoch 929/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14288.5601 - val_loss: 12458.3268\n",
      "Epoch 930/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14819.0479 - val_loss: 12861.2873\n",
      "Epoch 931/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 13920.4318 - val_loss: 12759.2584\n",
      "Epoch 932/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14030.5567 - val_loss: 16690.3853\n",
      "Epoch 933/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14995.1577 - val_loss: 12408.4145\n",
      "Epoch 934/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14364.7210 - val_loss: 13108.9323\n",
      "Epoch 935/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14219.7713 - val_loss: 12570.9672\n",
      "Epoch 936/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14441.0540 - val_loss: 12885.1096\n",
      "Epoch 937/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14052.5804 - val_loss: 12657.4459\n",
      "Epoch 938/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 13923.9323 - val_loss: 13260.1057\n",
      "Epoch 939/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 14013.6045 - val_loss: 13729.9309\n",
      "Epoch 940/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13959.4256 - val_loss: 12934.7212\n",
      "Epoch 941/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14320.5392 - val_loss: 13995.1145\n",
      "Epoch 942/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14821.987 - 1s 402us/step - loss: 14817.3598 - val_loss: 12546.6118\n",
      "Epoch 943/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 13632.6041 - val_loss: 12900.9206\n",
      "Epoch 944/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14375.1462 - val_loss: 12765.3758\n",
      "Epoch 945/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 14128.5347 - val_loss: 14432.7357\n",
      "Epoch 946/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14197.4131 - val_loss: 13281.8154\n",
      "Epoch 947/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14080.5850 - val_loss: 12181.3528\n",
      "Epoch 948/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14324.9667 - val_loss: 12349.6915\n",
      "Epoch 949/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14012.5511 - val_loss: 13018.6412\n",
      "Epoch 950/1000\n",
      "2304/2304 [==============================] - 1s 390us/step - loss: 14255.0074 - val_loss: 15873.9080\n",
      "Epoch 951/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14717.7372 - val_loss: 12762.9510\n",
      "Epoch 952/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13974.3436 - val_loss: 12546.4765\n",
      "Epoch 953/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14234.0405 - val_loss: 13405.9529\n",
      "Epoch 954/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14021.4645 - val_loss: 12466.7760\n",
      "Epoch 955/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 13925.6977 - val_loss: 13453.8253\n",
      "Epoch 956/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14474.5282 - val_loss: 12504.4543\n",
      "Epoch 957/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 13990.5396 - val_loss: 12301.0943\n",
      "Epoch 958/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 13936.6069 - val_loss: 13217.6736\n",
      "Epoch 959/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14229.4402 - val_loss: 12295.4087\n",
      "Epoch 960/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14244.5842 - val_loss: 12878.1249\n",
      "Epoch 961/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 13966.3603 - val_loss: 13099.1012\n",
      "Epoch 962/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14448.5880 - val_loss: 13052.2593\n",
      "Epoch 963/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13804.9836 - val_loss: 13043.3453\n",
      "Epoch 964/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14432.2674 - val_loss: 12421.3675\n",
      "Epoch 965/1000\n",
      "2304/2304 [==============================] - 1s 389us/step - loss: 13866.9203 - val_loss: 12710.0364\n",
      "Epoch 966/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14118.5367 - val_loss: 12608.4325\n",
      "Epoch 967/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13863.9051 - val_loss: 12497.9934\n",
      "Epoch 968/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14055.5219 - val_loss: 12798.6343\n",
      "Epoch 969/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14203.0176 - val_loss: 12626.2237\n",
      "Epoch 970/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14280.9816 - val_loss: 12754.1671\n",
      "Epoch 971/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13951.1702 - val_loss: 12712.6477\n",
      "Epoch 972/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14304.2816 - val_loss: 17329.0146\n",
      "Epoch 973/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 15169.8071 - val_loss: 12271.1659\n",
      "Epoch 974/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14481.7509 - val_loss: 13241.9281\n",
      "Epoch 975/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13924.4217 - val_loss: 13457.2602\n",
      "Epoch 976/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14402.3264 - val_loss: 12988.4250\n",
      "Epoch 977/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13917.5887 - val_loss: 14214.5680\n",
      "Epoch 978/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13851.6644 - val_loss: 14613.6863\n",
      "Epoch 979/1000\n",
      "2304/2304 [==============================] - 1s 375us/step - loss: 13638.6078 - val_loss: 12895.8128\n",
      "Epoch 980/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14048.2012 - val_loss: 15794.4410\n",
      "Epoch 981/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14248.7375 - val_loss: 12595.4897\n",
      "Epoch 982/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 13976.9222 - val_loss: 12944.9743\n",
      "Epoch 983/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 13878.1132 - val_loss: 14461.1452\n",
      "Epoch 984/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13750.8418 - val_loss: 13647.0555\n",
      "Epoch 985/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13821.2843 - val_loss: 15657.8466\n",
      "Epoch 986/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 387us/step - loss: 13951.3668 - val_loss: 12503.4262\n",
      "Epoch 987/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13732.6873 - val_loss: 12674.2793\n",
      "Epoch 988/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14143.0375 - val_loss: 12801.1951\n",
      "Epoch 989/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14586.6882 - val_loss: 13891.1528\n",
      "Epoch 990/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14043.9540 - val_loss: 12848.9969\n",
      "Epoch 991/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14709.4745 - val_loss: 13196.8980\n",
      "Epoch 992/1000\n",
      "2304/2304 [==============================] - 1s 379us/step - loss: 13989.1206 - val_loss: 13358.9111\n",
      "Epoch 993/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13895.6108 - val_loss: 12177.6148\n",
      "Epoch 994/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13983.3783 - val_loss: 12892.7427\n",
      "Epoch 995/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14490.0895 - val_loss: 14749.1190\n",
      "Epoch 996/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14125.6700 - val_loss: 13738.9878\n",
      "Epoch 997/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 14066.8977 - val_loss: 12453.9828\n",
      "Epoch 998/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 13551.5174 - val_loss: 14619.2152\n",
      "Epoch 999/1000\n",
      "2304/2304 [==============================] - 1s 386us/step - loss: 13681.4783 - val_loss: 12727.4434\n",
      "Epoch 1000/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14083.6308 - val_loss: 13065.0160\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
